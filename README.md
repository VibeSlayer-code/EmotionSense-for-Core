<div align="center">

# ğŸ§  EmotionSense  
### A Hybrid Transformer-LSTM Based Emotion Classifier Built for 2025 Core  
**By Vihaan Kanwar**  
_â€œUnderstand the unsaid.â€_

[![License](https://img.shields.io/badge/license-Apache_2.0-blue.svg)](LICENSE)
[![PyTorch](https://img.shields.io/badge/PyTorch-Enabled-red)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow)](https://huggingface.co/)
[![Model Version](https://img.shields.io/badge/Version-2.0-green)](#)

</div>

---

## ğŸš€ Overview

**EmotionSense** is a  hybrid emotion classification system designed for **natural language emotional understanding**, integrating:

- âš™ï¸ Transformer encoders (`RoBERTa-large`)
- ğŸ§¬ Sentence embeddings (`all-MiniLM-L6-v2`)
- ğŸ§  LSTM layers with attention pooling
- ğŸ”— Contextual keyword pattern matching
- ğŸ” LLM-assisted ensemble predictions

It intelligently fuses deep learning and rule-based NLP signals to ** detect 6 primary emotions**:
**Sadness, Joy, Love, Anger, Fear, Surprise.**

---

## ğŸ§° Technologies Used

| Layer             | Tech Stack                                     |
|------------------|------------------------------------------------|
| ğŸ§  Core Model     | PyTorch, HuggingFace Transformers              |
| ğŸ“š Sentence Embs | Sentence-Transformers (MiniLM-L6-v2)           |
| ğŸ“Š Data Handling | NumPy, JSON, Regex NLP, Torch AMP              |
| ğŸ¯ LLM Ensemble  | DistilRoBERTa Emotion Classifier via ğŸ¤— Hub     |
| ğŸ§ª Training Logs | Python Logging, Evaluation, Batch Inference     |


## ğŸ› ï¸ Run Locally

> ğŸ’¡ Make sure you have Python 3.10+ and a working GPU (recommended) with CUDA support.

### ğŸ“¦ Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/emotionsense.git
cd emotionsense
